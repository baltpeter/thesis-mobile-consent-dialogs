# Introduction

\markright{{\thechapter}. Introduction}

> Your privacy is important to us!
> 
> We use cookies to improve our writing. By reading this thesis, you consent to our processing of your personal data for analytics purposes. To opt out of this processing, please stop reading now.
> 
> [OK]

Consent and cookie notices seem ubiquitous both on the web and on mobile. They are an effort by publishers to comply with data protection legislation like the *General Data Protection Regulation* (GDPR), an EU regulation that went into force in 2018 and mandates strict legal guidelines for processing personal data. The flood of consent dialogs is often wrongly attributed as a shortcoming of the GDPR, when in fact the GDPR and other applicable data protection legislation provide strong consumer protections and set a high bar for what an acceptable way of collecting consent is, that many consent dialogs fail to meet. The ubiquity of consent dialogs is a manifestation of the common belief that consent is the only possible legal basis under the GDPR, which is not true unless data is used for tracking, as well as companies deliberately violating the law, e.g. by making use of nudging and dark patterns meant to coerce the user into giving consent and discouraging them from opting out.

The danger of such dark patterns and nudging is well established [@utzInformedConsentStudying2019a; @machuletzMultiplePurposesMultiple2020a; @forbrukerradetDeceivedDesign2018; @grasslDarkBrightPatterns2021; @grayDarkPatternsLegal2021], and on the web, there has already been pushback against these practices in the form of research identifying violations in consent dialogs [@utzInformedConsentStudying2019a; @matteCookieBannersRespect2020; @nouwensDarkPatternsGDPR2020] and consumer protection organisations like noyb bringing forward mass complaints against publishers using them [@noyb.euNoybAimsEnd2021]. Recently, in a joint decision with other EU data protection authorities, the Belgian authority ruled that the IAB Transparency & Consent Framework, an industry standard for collecting user consent and communicating consent status information to advertising and tracking scripts that is used on a majority of websites, violates the GDPR and is not able to acquire valid consent [@irishcouncilforcivillibertiesGDPREnforcerRules2022; @gegevensbeschermingsautoriteitlitigationchamberDecision2120222022].

At the same time, tracking is more common than ever not just on the web but also on mobile, with both Android and iOS apps regularly automatically transmitting telemetry data about device details (like model, settings, battery status, etc.), sensor data, events (which views are opened and buttons clicked?), or even the geolocation and which data is entered in the app [@trevisanYearsEUCookie2019a; @nguyenShareFirstAsk2021; @exoduscontributorsWhatExodusPrivacy2020; @geierAppChkCrowdSourcingPlatform2021; @kollnigAreIPhonesReally2022; @altpeterTheyTrackAutomated2021; @altpeterIOSWatchingYou2021]. Often, this data is sent to third-party companies and linked to the device's advertising identifier, a unique ID for a device that allows those companies to track users across multiple apps.

These practices are troubling from a data protection standpoint, not least since the GDPR also mandates strict legal guidelines for such data collection. According to those, any processing of personal data (meaning any data that can somehow be linked to a natural person, including pseudonymously) needs to have one of six possible legal bases. According to the data protection authorities, which are responsible for enforcing the GDPR in the EU, informed consent is the only applicable legal basis for tracking [@europeandataprotectionboardGuidelines2019Processing2019; @derlandesbeauftragtefurdendatenschutzunddieinformationsfreiheitbaden-wurttembergFAQCookiesUnd2022; @konferenzderunabhangigendatenschutzaufsichtsbehordendesbundesundderlanderOrientierungshilfeAufsichtsbehordenFur2021].  
This is further amplified by the *ePrivacy Directive* (ePD), another EU law which mandates information, consent, and opt-out requirements for accessing information stored on a user's device even when no personal data is processed, and the European Court of Justice's *Schrems II* ruling, which invalidated the *Privacy Shield* adequacy decision that data transfers to the US were usually based on.

We are now seeing first efforts by mobile operating system providers to limit the tracking done by apps. In late 2020, Apple introduced privacy labels on iOS, which require apps to self-label the affected categories of data being processed and the purposes of the processing [@appleinc.AppPrivacyDetails2021]. Since iOS 14.5, released in April 2021, Apple also provides users with a way to limit companies' ability to track them across apps: In order to gain access to the device's advertising ID (called *IDFA*  on iOS), apps now need to ask the user's permission, otherwise they can only access the *IDFV*, another ID which is unique per device and app vendor and as such does not allow tracking across different vendors [@appleinc.UserPrivacyData2021]. This was much to the dismay of advertisers and tracking companies having to face the reality that users do not want to be tracked, with one reporting opt-in rates as low as 2&nbsp;% [@laziukIOS14Optin2021] and Facebook anticipating a loss of $10 billion in sales revenue as a result [@newmanAppleMeta102022].  
Since then, Google has also gone in a similar direction on Android, allowing users to opt out of the advertising ID through the settings (rather than requiring opt-in as Apple did) [@vungleinc.WhatLimitAd2022] and starting to roll out "data safety" labels in late April 2022 [@freyGetMoreInformation2022]. 

As previous research on consent dialogs has so far almost exclusively been limited to the web, in this thesis, we study consent dialogs on Android and iOS in an automated and dynamic manner, analysing 4,388 popular apps from both platforms.

To do so, we first identify different types of consent elements in the apps and analyse their prevalence. Then, we identify violations by the apps based on a list of criteria for a legally compliant consent dialog that we have compiled from applicable legislation, court rulings, and recommendations by the German and EU-wide data protection authorities. We look for apps that violate these criteria by using dark patterns. We also measure the effect of the user's choice in the consent dialog by comparing the traffic from before any interaction with the traffic after accepting and rejecting the dialog. For this, we identify the contacted trackers and transmitted data types in the recorded traffic. Finally, we also compare the recorded network traffic on iOS against the apps' privacy labels. 

Contributions
:   Through this thesis, we make the following contributions:

1. We present a comprehensive list of criteria that a consent dialog needs to meet in order to be compliant with applicable data protection regulation in the EU, compiled from the law, court rulings, and data protection authority recommendations.
1. We quantify the use of the IAB Transparency & Consent Framework in mobile apps.
1. We developed a device instrumentation framework for Android and iOS that can manage apps, set app permissions and extract app preferences, collect the device network traffic (including HTTPS and certificate-pinned traffic), as well as analyse and interact with elements displayed on screen, building on our previous research on the subject of data protection in mobile apps.
1. We make an automated way to reliably download large amounts of iOS apps as IPA files publicly available for the first time, based on extending an existing open source tool that we contributed our changes back to.
1. We present a method for automatically detecting consent elements in Android and iOS apps, as well as identifying dark patterns in detected consent dialogs. We further present a method for extracting the actual transmitted data from recorded network traffic using tracking endpoint-specific adapters.
1. We identify that in our dataset of 2,068 apps on Android and 2,320 apps on iOS, more than 90&nbsp;% of consent dialogs implement at least one dark pattern and a majority of apps transmits tracking data regardless of consent status.
